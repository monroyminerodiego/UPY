{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fase B: Construcción del Dataset a Nivel Producto\n",
        "## Preparación de datos para clustering de productos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 1: Importación de librerías y carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv('../Data/Raw/train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 2: Limpieza de Item_Fat_Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores únicos en Item_Fat_Content después de limpieza:\n",
            "Item_Fat_Content\n",
            "Low Fat    5517\n",
            "Regular    3006\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Estandarizar valores de Item_Fat_Content\n",
        "fat_content_mapping = {\n",
        "    'Low Fat': 'Low Fat',\n",
        "    'low fat': 'Low Fat', \n",
        "    'LF': 'Low Fat',\n",
        "    'Regular': 'Regular',\n",
        "    'reg': 'Regular'\n",
        "}\n",
        "\n",
        "df['Item_Fat_Content'] = df['Item_Fat_Content'].map(fat_content_mapping)\n",
        "print(\"Valores únicos en Item_Fat_Content después de limpieza:\")\n",
        "print(df['Item_Fat_Content'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 3: Tratamiento inteligente de valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen de nulos después del tratamiento:\n",
            "Item_Identifier                 0\n",
            "Item_Weight                     0\n",
            "Item_Fat_Content                0\n",
            "Item_Visibility                 0\n",
            "Item_Type                       0\n",
            "Item_MRP                        0\n",
            "Outlet_Identifier               0\n",
            "Outlet_Establishment_Year       0\n",
            "Outlet_Size                  2410\n",
            "Outlet_Location_Type            0\n",
            "Outlet_Type                     0\n",
            "Item_Outlet_Sales               0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Para Item_Weight: Buscar el peso del mismo Item_Identifier en otras filas\n",
        "def fill_item_weight(row):\n",
        "    if pd.isna(row['Item_Weight']):\n",
        "        same_item_weights = df[df['Item_Identifier'] == row['Item_Identifier']]['Item_Weight']\n",
        "        same_item_weights = same_item_weights.dropna()\n",
        "        if len(same_item_weights) > 0:\n",
        "            return same_item_weights.iloc[0]\n",
        "    return row['Item_Weight']\n",
        "\n",
        "df['Item_Weight'] = df.apply(fill_item_weight, axis=1)\n",
        "\n",
        "# Para visibilidad 0: tratarlos como nulos e imputar con promedio del producto\n",
        "df['Item_Visibility'] = df['Item_Visibility'].replace(0, np.nan)\n",
        "\n",
        "def fill_item_visibility(row):\n",
        "    if pd.isna(row['Item_Visibility']):\n",
        "        same_item_visibility = df[df['Item_Identifier'] == row['Item_Identifier']]['Item_Visibility']\n",
        "        same_item_visibility = same_item_visibility.dropna()\n",
        "        if len(same_item_visibility) > 0:\n",
        "            return same_item_visibility.mean()\n",
        "    return row['Item_Visibility']\n",
        "\n",
        "df['Item_Visibility'] = df.apply(fill_item_visibility, axis=1)\n",
        "\n",
        "# Para los nulos restantes, usar mediana por tipo de producto\n",
        "weight_imputer = SimpleImputer(strategy='median')\n",
        "df['Item_Weight'] = weight_imputer.fit_transform(df[['Item_Weight']])\n",
        "\n",
        "visibility_imputer = SimpleImputer(strategy='median')\n",
        "df['Item_Visibility'] = visibility_imputer.fit_transform(df[['Item_Visibility']])\n",
        "\n",
        "print(\"Resumen de nulos después del tratamiento:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 4: Feature Engineering - Crear categorías amplias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribución de categorías amplias:\n",
            "Item_Category_Broad\n",
            "Food              6125\n",
            "Non-Consumable    1599\n",
            "Drink              799\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución de Fat_Content después del ajuste:\n",
            "Item_Fat_Content\n",
            "Low Fat           3918\n",
            "Regular           3006\n",
            "Not Applicable    1599\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Crear categoría amplia basada en las primeras dos letras del ID\n",
        "def get_broad_category(item_id):\n",
        "    prefix = item_id[:2]\n",
        "    if prefix == 'FD':\n",
        "        return 'Food'\n",
        "    elif prefix == 'DR':\n",
        "        return 'Drink'\n",
        "    elif prefix == 'NC':\n",
        "        return 'Non-Consumable'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "df['Item_Category_Broad'] = df['Item_Identifier'].apply(get_broad_category)\n",
        "\n",
        "# Ajustar Fat_Content para productos no consumibles\n",
        "df.loc[df['Item_Category_Broad'] == 'Non-Consumable', 'Item_Fat_Content'] = 'Not Applicable'\n",
        "\n",
        "print(\"Distribución de categorías amplias:\")\n",
        "print(df['Item_Category_Broad'].value_counts())\n",
        "print(\"\\nDistribución de Fat_Content después del ajuste:\")\n",
        "print(df['Item_Fat_Content'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 5: Construcción del dataset agregado a nivel producto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset agregado: (1559, 12)\n",
            "\n",
            "Primeras filas del dataset agregado:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item_Identifier</th>\n",
              "      <th>Total_Sales</th>\n",
              "      <th>Avg_Sales</th>\n",
              "      <th>Store_Count</th>\n",
              "      <th>Avg_MRP</th>\n",
              "      <th>Avg_Visibility</th>\n",
              "      <th>Item_Weight</th>\n",
              "      <th>Item_Fat_Content</th>\n",
              "      <th>Item_Type</th>\n",
              "      <th>Item_Category_Broad</th>\n",
              "      <th>Sales_Per_Store</th>\n",
              "      <th>Price_Per_Unit_Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DRA12</td>\n",
              "      <td>11061.6012</td>\n",
              "      <td>1843.600200</td>\n",
              "      <td>6</td>\n",
              "      <td>141.865400</td>\n",
              "      <td>0.047934</td>\n",
              "      <td>11.600</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>Drink</td>\n",
              "      <td>1843.600200</td>\n",
              "      <td>12.229776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DRA24</td>\n",
              "      <td>15723.5328</td>\n",
              "      <td>2246.218971</td>\n",
              "      <td>7</td>\n",
              "      <td>164.086800</td>\n",
              "      <td>0.048062</td>\n",
              "      <td>19.350</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>Drink</td>\n",
              "      <td>2246.218971</td>\n",
              "      <td>8.479938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DRA59</td>\n",
              "      <td>20915.4412</td>\n",
              "      <td>2614.430150</td>\n",
              "      <td>8</td>\n",
              "      <td>185.179900</td>\n",
              "      <td>0.153963</td>\n",
              "      <td>8.270</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>Drink</td>\n",
              "      <td>2614.430150</td>\n",
              "      <td>22.391765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DRB01</td>\n",
              "      <td>4554.0720</td>\n",
              "      <td>1518.024000</td>\n",
              "      <td>3</td>\n",
              "      <td>189.586333</td>\n",
              "      <td>0.082126</td>\n",
              "      <td>7.390</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>Drink</td>\n",
              "      <td>1518.024000</td>\n",
              "      <td>25.654443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DRB13</td>\n",
              "      <td>12144.1920</td>\n",
              "      <td>2428.838400</td>\n",
              "      <td>5</td>\n",
              "      <td>189.693000</td>\n",
              "      <td>0.008002</td>\n",
              "      <td>6.115</td>\n",
              "      <td>Regular</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>Drink</td>\n",
              "      <td>2428.838400</td>\n",
              "      <td>31.020932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Item_Identifier  Total_Sales    Avg_Sales  Store_Count     Avg_MRP  \\\n",
              "0           DRA12   11061.6012  1843.600200            6  141.865400   \n",
              "1           DRA24   15723.5328  2246.218971            7  164.086800   \n",
              "2           DRA59   20915.4412  2614.430150            8  185.179900   \n",
              "3           DRB01    4554.0720  1518.024000            3  189.586333   \n",
              "4           DRB13   12144.1920  2428.838400            5  189.693000   \n",
              "\n",
              "   Avg_Visibility  Item_Weight Item_Fat_Content    Item_Type  \\\n",
              "0        0.047934       11.600          Low Fat  Soft Drinks   \n",
              "1        0.048062       19.350          Regular  Soft Drinks   \n",
              "2        0.153963        8.270          Regular  Soft Drinks   \n",
              "3        0.082126        7.390          Low Fat  Soft Drinks   \n",
              "4        0.008002        6.115          Regular  Soft Drinks   \n",
              "\n",
              "  Item_Category_Broad  Sales_Per_Store  Price_Per_Unit_Weight  \n",
              "0               Drink      1843.600200              12.229776  \n",
              "1               Drink      2246.218971               8.479938  \n",
              "2               Drink      2614.430150              22.391765  \n",
              "3               Drink      1518.024000              25.654443  \n",
              "4               Drink      2428.838400              31.020932  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Agrupar por producto y calcular métricas agregadas\n",
        "product_aggregated = df.groupby('Item_Identifier').agg({\n",
        "    'Item_Outlet_Sales': ['sum', 'mean'],\n",
        "    'Outlet_Identifier': 'nunique',\n",
        "    'Item_MRP': 'mean',\n",
        "    'Item_Visibility': 'mean',\n",
        "    'Item_Weight': 'mean',\n",
        "    'Item_Fat_Content': 'first',\n",
        "    'Item_Type': 'first',\n",
        "    'Item_Category_Broad': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "# Renombrar columnas para mayor claridad\n",
        "product_aggregated.columns = [\n",
        "    'Item_Identifier',\n",
        "    'Total_Sales',\n",
        "    'Avg_Sales',\n",
        "    'Store_Count',\n",
        "    'Avg_MRP',\n",
        "    'Avg_Visibility',\n",
        "    'Item_Weight',\n",
        "    'Item_Fat_Content',\n",
        "    'Item_Type',\n",
        "    'Item_Category_Broad'\n",
        "]\n",
        "\n",
        "# Calcular métricas adicionales\n",
        "product_aggregated['Sales_Per_Store'] = product_aggregated['Total_Sales'] / product_aggregated['Store_Count']\n",
        "product_aggregated['Price_Per_Unit_Weight'] = product_aggregated['Avg_MRP'] / product_aggregated['Item_Weight']\n",
        "\n",
        "print(f\"Dataset agregado: {product_aggregated.shape}\")\n",
        "print(\"\\nPrimeras filas del dataset agregado:\")\n",
        "product_aggregated.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 6: Encoding y Scaling para clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset para modelado (primeras filas):\n",
            "   log_Total_Sales  log_Avg_Sales  Store_Count   Avg_MRP  log_Avg_Visibility  \\\n",
            "0         0.182047      -0.026613     0.348838  0.013769           -0.463337   \n",
            "1         0.698677       0.302109     1.003278  0.371701           -0.460515   \n",
            "2         1.117845       0.554748     1.657717  0.711459            1.763570   \n",
            "3        -1.121573      -0.349946    -1.614480  0.782436            0.278502   \n",
            "4         0.319212       0.432198    -0.305601  0.784154           -1.360979   \n",
            "\n",
            "   Item_Weight  Sales_Per_Store  Price_Per_Unit_Weight Item_Identifier  \n",
            "0    -0.260117        -0.308001              -0.068270           DRA12  \n",
            "1     1.408477         0.047767              -0.534033           DRA24  \n",
            "2    -0.977074         0.373131               1.193937           DRA59  \n",
            "3    -1.166540        -0.595691               1.599190           DRB01  \n",
            "4    -1.441051         0.209136               2.265755           DRB13  \n",
            "\n",
            "Shape del dataset para modelado: (1559, 9)\n"
          ]
        }
      ],
      "source": [
        "# Crear copia para interpretación (sin escalar)\n",
        "product_interpretation = product_aggregated.copy()\n",
        "\n",
        "# Seleccionar variables para clustering\n",
        "clustering_vars = [\n",
        "    'Total_Sales', 'Avg_Sales', 'Store_Count', 'Avg_MRP', \n",
        "    'Avg_Visibility', 'Item_Weight', 'Sales_Per_Store', 'Price_Per_Unit_Weight'\n",
        "]\n",
        "\n",
        "# Aplicar log-transform a variables sesgadas\n",
        "skewed_vars = ['Total_Sales', 'Avg_Sales', 'Avg_Visibility']\n",
        "for var in skewed_vars:\n",
        "    product_aggregated[f'log_{var}'] = np.log1p(product_aggregated[var])\n",
        "\n",
        "# Actualizar variables de clustering\n",
        "clustering_vars_transformed = [f'log_{var}' if var in skewed_vars else var for var in clustering_vars]\n",
        "\n",
        "# Escalar variables\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(product_aggregated[clustering_vars_transformed])\n",
        "\n",
        "# Crear dataset para modelado\n",
        "product_modeling = pd.DataFrame(scaled_features, columns=clustering_vars_transformed)\n",
        "product_modeling['Item_Identifier'] = product_aggregated['Item_Identifier']\n",
        "\n",
        "# Encoding de variables categóricas para análisis\n",
        "label_encoders = {}\n",
        "categorical_vars = ['Item_Fat_Content', 'Item_Type', 'Item_Category_Broad']\n",
        "\n",
        "for var in categorical_vars:\n",
        "    le = LabelEncoder()\n",
        "    product_interpretation[f'{var}_encoded'] = le.fit_transform(product_interpretation[var])\n",
        "    label_encoders[var] = le\n",
        "\n",
        "print(\"Dataset para modelado (primeras filas):\")\n",
        "print(product_modeling.head())\n",
        "print(f\"\\nShape del dataset para modelado: {product_modeling.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 7: Guardar datasets procesados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Datasets guardados exitosamente:\n",
            "  - product_modeling_dataset_deep.csv (para clustering)\n",
            "  - product_interpretation_dataset_deep.csv (para análisis)\n"
          ]
        }
      ],
      "source": [
        "# Guardar datasets\n",
        "product_modeling.to_csv('../Data/Processed/product_modeling_dataset_deep.csv', index=False)\n",
        "product_interpretation.to_csv('../Data/Processed/product_interpretation_dataset_deep.csv', index=False)\n",
        "\n",
        "print(\"✓ Datasets guardados exitosamente:\")\n",
        "print(\"  - product_modeling_dataset_deep.csv (para clustering)\")\n",
        "print(\"  - product_interpretation_dataset_deep.csv (para análisis)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paso 8: Resumen de transformaciones aplicadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== RESUMEN DE TRANSFORMACIONES APLICADAS ===\n",
            "\n",
            "1. Limpieza de Item_Fat_Content: Estandarización de valores inconsistentes (Low Fat, LF, low fat → Low Fat; Regular, reg → Regular)\n",
            "2. Tratamiento de Item_Weight nulos: Imputación usando valores del mismo producto, luego mediana por tipo de producto\n",
            "3. Tratamiento de Item_Visibility cero: Valores 0 tratados como nulos e imputados con promedio del mismo producto\n",
            "4. Feature Engineering: Creación de Item_Category_Broad (Food/Drink/Non-Consumable) basado en prefijos del ID\n",
            "5. Ajuste lógico: Fat_Content marcado como 'Not Applicable' para productos no consumibles\n",
            "6. Agregación a nivel producto: Cálculo de 8 métricas clave por producto incluyendo ventas totales, promedio y penetración\n",
            "7. Transformación de variables: Aplicación de log-transform a variables sesgadas (Total_Sales, Avg_Sales, Avg_Visibility)\n",
            "8. Escalado: Normalización StandardScaler para todas las variables numéricas\n",
            "9. Encoding: Label encoding para variables categóricas en dataset de interpretación\n",
            "10. Creación de datasets: 2 datasets: product_modeling_dataset (scaled) y product_interpretation_dataset (raw + encoded)\n",
            "\n",
            "=== RESULTADOS FINALES ===\n",
            "• Productos únicos procesados: 1559\n",
            "• Variables para clustering: 8\n",
            "• Variables categóricas codificadas: 3\n",
            "• Datasets generados: 2 (modelado + interpretación)\n"
          ]
        }
      ],
      "source": [
        "print(\"=== RESUMEN DE TRANSFORMACIONES APLICADAS ===\\n\")\n",
        "\n",
        "transformations = [\n",
        "    (\"Limpieza de Item_Fat_Content\", \"Estandarización de valores inconsistentes (Low Fat, LF, low fat → Low Fat; Regular, reg → Regular)\"),\n",
        "    (\"Tratamiento de Item_Weight nulos\", \"Imputación usando valores del mismo producto, luego mediana por tipo de producto\"),\n",
        "    (\"Tratamiento de Item_Visibility cero\", \"Valores 0 tratados como nulos e imputados con promedio del mismo producto\"),\n",
        " (\"Feature Engineering\", \"Creación de Item_Category_Broad (Food/Drink/Non-Consumable) basado en prefijos del ID\"),\n",
        "    (\"Ajuste lógico\", \"Fat_Content marcado como 'Not Applicable' para productos no consumibles\"),\n",
        "    (\"Agregación a nivel producto\", \"Cálculo de 8 métricas clave por producto incluyendo ventas totales, promedio y penetración\"),\n",
        "    (\"Transformación de variables\", \"Aplicación de log-transform a variables sesgadas (Total_Sales, Avg_Sales, Avg_Visibility)\"),\n",
        "    (\"Escalado\", \"Normalización StandardScaler para todas las variables numéricas\"),\n",
        "    (\"Encoding\", \"Label encoding para variables categóricas en dataset de interpretación\"),\n",
        "    (\"Creación de datasets\", \"2 datasets: product_modeling_dataset (scaled) y product_interpretation_dataset (raw + encoded)\")\n",
        "]\n",
        "\n",
        "for i, (step, description) in enumerate(transformations, 1):\n",
        "    print(f\"{i}. {step}: {description}\")\n",
        "\n",
        "print(f\"\\n=== RESULTADOS FINALES ===\")\n",
        "print(f\"• Productos únicos procesados: {len(product_aggregated)}\")\n",
        "print(f\"• Variables para clustering: {len(clustering_vars_transformed)}\")\n",
        "print(f\"• Variables categóricas codificadas: {len(categorical_vars)}\")\n",
        "print(f\"• Datasets generados: 2 (modelado + interpretación)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
