{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values with Pandas - Class Activity\n",
    "\n",
    "## Instructions given by professor\n",
    "\n",
    "The tasks are the following:\n",
    "- Load Data\n",
    "- Delete features with more than 70% missing values\n",
    "- Delete observations with more than 50% missing values\n",
    "- Check for duplicated rows\n",
    "- Delete features with average equal to Zero\n",
    "- Identify Type of data of each feature\n",
    "- Validate that Numbers are numeric values\n",
    "- Identify Categorical Features --> Generate the corresponding Dummy columns\n",
    "\n",
    "* Finally, you should execute the same code, now loading the dataset called \"test.csv\"\n",
    "\n",
    "The Jupyter Notebook (.ipynb) should be submited next to the export of such code, as html or PDF, with all code executed and outputs visible.\n",
    "\n",
    "Be sure to alternate code and text cells, with the text cells explaining the code and results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development\n",
    "\n",
    "### Load Data\n",
    "In this part, we import al the libraries that we are going to need and the dataframe that we are going to analize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  225 non-null    int64 \n",
      " 1   time        225 non-null    object\n",
      " 2   carrera     225 non-null    object\n",
      " 3   acepta      225 non-null    object\n",
      " 4   positivo    225 non-null    object\n",
      " 5   negativo    225 non-null    object\n",
      " 6   edad        225 non-null    int64 \n",
      " 7   sexo        225 non-null    object\n",
      " 8   trabajo     225 non-null    object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 15.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../DataBases/ModalidadVirtual.csv',delimiter=',')\n",
    "print(df.info()) #With method \".info()\" we can summarize the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete features with more than 70% missing values\n",
    "To remove features/columns with more than 70% missing values, the following procedure was followed:\n",
    "\n",
    "1. Declare a list of the dataframe's column names.\n",
    "2. Iterate through the previously created list in a for loop to create a variable with the information from each column of the dataframe.\n",
    "3. Create a variable to store the number of data points in the column.\n",
    "4. Create a variable to store the number of missing values in the column.\n",
    "5. Calculate the percentage of missing values.\n",
    "6. If the percentage of missing values is greater than 70%, remove the feature from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_list = df.columns.tolist()\n",
    "for header in headers_list:\n",
    "    feature = df[header]\n",
    "    len_feature = len(feature)\n",
    "    num_missing_features = (feature.isnull()).sum()\n",
    "    percentage_missing_features = (num_missing_features * 100) / len_feature\n",
    "    if percentage_missing_features >= 70: df = df.drop(header,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete observations with more than 50% missing values\n",
    "To remove observations/rows with more than 50% missing values, the following procedure was followed:\n",
    "\n",
    "1. Declare a variable with the number of observations in the dataframe.\n",
    "2. Iterate through a for loop, where the variable 'row' is declared as an index to identify each observation.\n",
    "3. Create a variable to store each observation.\n",
    "4. Declare the variable of the number of data points in that observation and another variable that stores the number of missing data points in the same.\n",
    "5. Create a variable that stores the percentage of missing values in the dataframe.\n",
    "6. If the percentage of missing values in each observation is greater than 50%, then that observation is deleted from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = len(df)\n",
    "for row in range(len_df):\n",
    "    observation = df.loc[row]\n",
    "    len_observation = len(observation)\n",
    "    num_missing_observations = (observation.isnull()).sum()\n",
    "    percentage_missing_observations = (num_missing_observations * 100) / len_observation\n",
    "    if percentage_missing_observations >= 50: df = df.drop([row], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicated rows\n",
    "To remove duplicate rows:\n",
    "\n",
    "1. Create a list to store the indices of the duplicate rows and create the variable responsible for updating its value according to the current index.\n",
    "2. In a for loop, iterate over the observations in the dataframe to identify repeated rows and return 'True ' if any row is repeated.\n",
    "3. If the row is repeated, then add the index to the list of duplicate rows.\n",
    "4. Remove all rows from the dataframe that are in the previously created list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_row_list = []\n",
    "iteration_index = 0\n",
    "for row in df.duplicated():\n",
    "    if row: duplicated_row_list.append(iteration_index)\n",
    "    iteration_index += 1\n",
    "df = df.drop(duplicated_row_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete features with Average = 0\n",
    "In a for loop, the list of dataframe headers is iterated over and the process for each iteration is as follows:\n",
    "\n",
    "1. Create a list of possible values for each feature.\n",
    "2. Create a variable to store the information of the feature to be analyzed.\n",
    "3. In a nested for loop, the feature is iterated over to access each observation of the same.\n",
    "4. If the value of our observation is not in the list of possible values, then add that value to the list.\n",
    "5. If the length of the list of possible values is the same size as our observations, it means that that feature receives unique data, so we discard that feature and move on to the next one.\n",
    "6. If there are fewer possible values than the length of the dataframe, then a variable is created to store the average of that feature.\n",
    "7. A for loop is used to iterate over the list of possible values of the feature and the number of times that data repeats is summed.\n",
    "8. With the sum of how many times the data appears in the dataframe, it is divided by the length of the list of possible values to obtain the average of the feature.\n",
    "9. If the average of the feature is equal to 0, then that feature is removed from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_list = df.columns.tolist()\n",
    "for header in headers_list:\n",
    "    possible_value_list = []\n",
    "    feature = df[header]\n",
    "    for observation in feature:\n",
    "        if not(observation in possible_value_list): possible_value_list.append(observation)\n",
    "    if len(possible_value_list) == len(feature): continue\n",
    "    average = 0\n",
    "    for value in possible_value_list: average += (df[header] == value).sum()\n",
    "    average /= len(possible_value_list)\n",
    "    if average == 0: df = df.drop(header,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify type of data of each feature\n",
    "To identify the data type of each feature, a for loop is used to iterate over the list of headers to print the information of each feature separately. This facilitates the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: Unnamed: 0\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "222 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.9 KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: time\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: carrera\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: acepta\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: positivo\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: negativo\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: edad\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "222 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.9 KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: sexo\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Series name: trabajo\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "222 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for header in headers_list:\n",
    "    print(f'{df[header].info()}\\n\\n{\"*\"*50}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate that numbers are numeric Values\n",
    "The process of validating numeric data of features is as follows:\n",
    "\n",
    "1. The list of dataframe headers is iterated over in a for loop.\n",
    "2. Three variables are created to keep track of the number of integers, floats, and any other type of data.\n",
    "3. The information of the dataframe is stored for each feature.\n",
    "4. The feature is iterated over to access each observation, and then a validation is performed that updates the value of the three variables that keep track of integers, floats, or other types of data, depending on the data type of the observation.\n",
    "5. If the sum of the total integers and floats is not greater than the count of any other type of data, we can infer that that feature should be something other than numeric values, so we omit that feature and continue with the next one.\n",
    "6. A validation is performed depending on which value is greater, the count of integers or floats, in order to then unify the data type of the entire feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_list = df.columns.tolist()\n",
    "for header in headers_list:\n",
    "    int_count, float_count, other_count = 0, 0, 0\n",
    "    feature = df[header]\n",
    "    for observation in feature:\n",
    "        if (type(observation) == int) or (type(observation) == float): \n",
    "            int_count += 1 if type(observation) == int else 0\n",
    "            float_count += 1 if type(observation) == float else 0\n",
    "        else: other_count += 1\n",
    "    if not((int_count+float_count) > other_count): continue\n",
    "    if int_count > float_count:\n",
    "        df[header] = df[header].astype('int64')\n",
    "    if float_count > int_count:\n",
    "        df[header] = df[header].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify categorical features → Generate dummies\n",
    "To identify categorical features, a for loop is used to iterate over the list of dataframe headers. With the objective of making it easier to analyze, the \".get_dummies()\" method is used, which is incorporated with pandas. The parameters needed are the dataframe and the column to generate the dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0        time                       carrera acepta  \\\n",
      "0             0  2020-11-08        Ingeniería de Sistemas     Si   \n",
      "1             1  2020-11-08                    Psicología     Si   \n",
      "2             2  2020-11-08        Ingeniería de Sistemas     Si   \n",
      "3             3  2020-11-08        Ingeniería de Sistemas     Si   \n",
      "4             4  2020-11-08        Ingeniería de Sistemas     Si   \n",
      "..          ...         ...                           ...    ...   \n",
      "217         230  2020-12-10  Gestión Turística y Hotelera     Si   \n",
      "218         231  2020-12-11        Ingeniería de Sistemas     No   \n",
      "219         232  2020-12-11  Gestión Turística y Hotelera     No   \n",
      "220         233  2020-12-11         Ingeniería Agronómica     Si   \n",
      "221         234  2020-12-12        Comercio Internacional     Si   \n",
      "\n",
      "                          positivo  \\\n",
      "0                Horario flexible.   \n",
      "1    Acceso desde cualquier lugar.   \n",
      "2                Horario flexible.   \n",
      "3                Horario flexible.   \n",
      "4    Acceso desde cualquier lugar.   \n",
      "..                             ...   \n",
      "217              Horario flexible.   \n",
      "218  Acceso desde cualquier lugar.   \n",
      "219              Horario flexible.   \n",
      "220  Acceso desde cualquier lugar.   \n",
      "221              Horario flexible.   \n",
      "\n",
      "                                              negativo  edad    sexo  \\\n",
      "0               Contacto Personal Docente-Estudiantil.    20  Hombre   \n",
      "1               Contacto Personal Docente-Estudiantil.    26  Hombre   \n",
      "2    Falta de recursos de calidad(plataformas, doce...    20   Mujer   \n",
      "3                                 Conexión a internet.    18   Mujer   \n",
      "4               Contacto Personal Docente-Estudiantil.    39  Hombre   \n",
      "..                                                 ...   ...     ...   \n",
      "217                               Conexión a internet.    19   Mujer   \n",
      "218  Falta de recursos de calidad(plataformas, doce...    23   Mujer   \n",
      "219  Falta de recursos de calidad(plataformas, doce...    25  Hombre   \n",
      "220             Contacto Personal Docente-Estudiantil.    20   Mujer   \n",
      "221  Falta de recursos de calidad(plataformas, doce...    23  Hombre   \n",
      "\n",
      "     trabajo_Eventual  trabajo_No  trabajo_Sí  \n",
      "0                   1           0           0  \n",
      "1                   1           0           0  \n",
      "2                   0           0           1  \n",
      "3                   0           1           0  \n",
      "4                   0           0           1  \n",
      "..                ...         ...         ...  \n",
      "217                 0           0           1  \n",
      "218                 0           1           0  \n",
      "219                 0           0           1  \n",
      "220                 0           0           1  \n",
      "221                 0           0           1  \n",
      "\n",
      "[222 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f'{pd.get_dummies(df,columns=[header])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made By\n",
    "- Diego Monroy Minero\n",
    "- Sergio Johanan Barrera Chan\n",
    "- Juan Antonio Cel Vazquez\n",
    "- Ariel Joel Buenfil Góngora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
